```
오늘은 자바 컴파일 개념
kafka Cluster 설치 실습
기본 개념
Kafka Internal
진행합니다.
```

7/2 김태완 강사님
* 자바를 많이 사용하는 이유
- 자바가 관리하기가 되게 좋다. 공동 프로젝트하기 좋다. 
- 그러나 효율적이지 않은 부분이 꽤 있다. 
- 국내의 it 환경이, 기형적으로 발전한 것은 사실이다. 삼성sds, sk cnc
- 각 회사 공통부서가 전산실 개념을 떼어 내서, 하나의 회사를 만듦
- 돈을 굴리는 것에 대해서 그룹사가 많은 고민을 함
- 사실은 여기서 관리체계를 서비스로 판매함. it에 대해서 sw판매함. 
- 오라클: 삼성전자 db 직접 납품을 못함. si 업체를 껴야 한다. 
- 장점: 적응이 되게 빠름. 하지만 그룹사 내에서는 매출 증가. 
- 100~200명이 한꺼번에 공동개발을 인터페이스를 통해서, 표준화/오픈소스가 되어있는걸 모듈화가 되어있고,개발하기 편한 구조로 되어있다.

- 기술을 선택할 때, 사용자가 많아야 한다. 그걸로 돈 버는 회사가 많아야한다. (자바로 돈 버는 회사 많음) 
- 자바를 스폰하는 회사 오라클. 안정성 
- 단점? : 무겁다, 코드가 길다 -> 반복적인 코드(보일러플레이트 코드)-> 코틀린 생겨남
  - 지원하는 유틸리티가 많아서. 라이브러리 Jar :java archive
- JIT: Just In time : 필요한 부분만, 바이트 코드로 바꾼다. 
- 자바 15~30% 100대-> 85대 정도까지 줄일 수 있다고 비유하면. 
- 그루비, 스칼라, 코틀린의 3가지 공통점 : Java를 기반으로 만든 언어다. 
- 자바 위에서 R, JS, Ruby, C, C++, Rust, Python 등.. API 레벨이 상호 호출가능하도록. 
- 3) native Image : jar파일을 만들어서, jar를 실행시키는 것. 기본적으로 자바가 깔려있어야 하는데, 자바프로그램을 native-image 기계어가 만들어버림. jit 컴파일러 정적. 
- java가 class를 컨버트, 로딩하는 과정의 시간을 웜업이라고 하는데 그걸 해소하기 위해 native를 씀.
- war파일을 기계어로 만드는데 native-image 해볼 것이다. 

키워드로 동향을 파악할 수 있다. 
- 개발자 세미나, 컨퍼런스 다니는 게 좋다. 
- C1: java 실행할 때, 하나 고정해서 썼었는데, 요즘엔 융합해서 C2도 같이 사용한다. 
- 특징: 엄청 빠름. 실행시키는 것에 집중함. 그러나 코드 최적화가 약하다. 
- C2: 굼뜨다. 통계값 만들고 
- GraalVM: C2를 graalvm으로 바꿈. c1 추가 유지보수가 어려워짐. 
- 바이너리코드로 바꾸는 graal이라는 컴파일러를 자바로 만들었다보니, 새로운 성능 최적화를 다형성으로 찍어 넣는 것이 좋아진다. 
- 양수열님이 다형성. 객체 상속. 
- 객체지향을 잘 쓴다는 것 -> if 문이 적다. 
- JVMCI: 컴파일러에 대한 인터페이스  -> Graalvm 계속 기능을 추가해나갈 수 있다.
- 기존의 자바에 Graal을 대체해 확장시킨 것이다. 

if문 했는데... 1은 0보다 크다. 논리적으로 100% 당연한 조건문 쓰는 경우가 되게 많다. 
동작하지 않는 콜스택
- 콜스택이라는 건 실행한다는건데, 
- 세번째는 절대로 실행하지 않는 if문(항상false), 
- 스프링부트 프로젝트에서 GraalVM으로 전환하는게 최종 목표이다. 
- JIT 컴파일러는 실행할 때
- 실행 전에 기계어를 만든다. 

- 데이터 migration 어떻게 넘어갈까? 
- OS에 나눠져 있는 블록 -> 끼워맞춰짐 하나의 이미지 
- 

spring - > graalvm
- spring native로

어떤 사람은 정리해서 발표하는 역할, 더 잘함에도 불구하고 가서 들으면서 정보를 수집하시는 분들이 있다.
가능하면, 개발자 커리어를 가져간다면 방점을 찍는 것이 중요하다.
정리라면, 나중에 검색 가능하고 지속적으로 확인 가능한 곳에 저장하는 것이 중요하다. 
notion 등도 좋지만, 블로그, youtube 라던지.. '나'라는 곳을 어필하는 게 중요하다. 
오프라인에서 나눔같은걸 하면 좋다 

프로듀서와 컨슈머 역할의 분리
데이터가 흘러가는 모든 영역에서 다 처리할 수 있다. 
데이터와 이벤트 뭐가 다를가? 같은 것, 이벤트는 어떤 기능을 구현하는 함수, function 등 매개변수로 들어가는 게 있으면 이벤트라고 칭하는 경우가 많다. 
hadoop
vertica

아는만큼 보이는 건 어려움. 하지만, 습관적으로 맥락 이해 못하는 것이 있다면 찾아보는 것이 좋다. 
- it 기술책을 읽었는데, 무슨 말인지 모르겠어.. 국내 it 특성상 번역이 잘못되어 있을 수 있음. 
- 명사를 잘못 생각하고 있는 것. 
자바 framework에서의 컨텍스트를 동일한 단어지만, 다른 명사로 인식하고 이해해야 한다. 
책을 읽었을 때 이해 안가는것은.. 
- 어떤 키워드가 막히는 것들을 찾아봐야한다. 꼬리에 꼬리를 물다 보면,, 한도 끝도 없는 경우가 있지만.. 
카프카란? - 분산 처리, 메시지 큐, 라이트하게 좋은 구조가 카프카다. 소설가 이름을 차용함. 

프리티어 - 한국 리전이 out of capacity 
무료 사용하려면, tokyo리전 


log.dirs=/tmp/kafka-logs
zookeeper.connect=10.0.11.182:2181,10.0.7.76:2181,10.0.10.33:2181

zoo01 10.0.11.182
zoo02 10.0.7.76
zoo03 10.0.10.33

mysql  서버 설치 
두 팀으로 나눠서, mysql 로 설치 


kafka01 10.0.11.206
kafka02 10.0.15.30
kafka03 10.0.4.60

./kafka/bin/kafka-topics.sh --bootstrap-server 10.0.11.206:9092,10.0.15.30:9092,10.0.4.60:9092 --topic demo5-topic --partitions 1 --replication-factor 3 --create
---> demo5-topic 생성 (kafka01, kafka02, kafka03 의 프라이빗 IPv4 주소)

./kafka/bin/kafka-topics.sh --bootstrap-server 43.207.2.102:9092,43.207.162.198:9092,54.248.14.232:9092 --topic demo6-topic --partitions 1 --replication-factor 3 --create
---> demo6-topic 생성 (kafka01, kafka02, kafka03 의 퍼블릭 주소)

./kafka/bin/kafka-topics.sh --bootstrap-server 10.0.11.206:9092,10.0.15.30:9092,10.0.4.60:9092 --topic demo5-topic --partitions 1 --replication-factor 3 --create

kafka01 43.207.2.102
kafka02 43.207.162.198
kafka03 54.248.14.232

./kafka/bin/kafka-topics.sh --bootstrap-server 43.207.2.102:9092,43.207.162.198:9092,54.248.14.232:9092 --topic demo6-topic --partitions 1 --replication-factor 3 --create
---> demo6-topic 생성 (kafka01, kafka02, kafka03 의 퍼블릭 주소)

서브넷 구성하는 법.. certification 가장 많이 나오는 문자

p120부터쯤
ps -ef|grep java
pkill -9 -ef java
wget https://raw.githubusercontent.com/taewanme/kbi-demo/main/kafka.service
sudo mv ./kafka.service /etc/systemd/system/
sudo chown root:root /etc/systemd/system/kafka.service

p134
sudo systemctl daemon-reload
sudo systemctl enable kafka.service
sudo systemctl start kafka.service
sudo systemctl status kafka.service


sudo mv ./zookeeper.service /etc/systemd/system/
sudo chown root:root /etc/systemd/system/zookeeper.service

sudo systemctl daemon-reload
sudo systemctl enable zookeeper.service
sudo systemctl start zookeeper.service
sudo systemctl status zookeeper.service